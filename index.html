<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Client-Side Transcription</title>
  
  <!-- Bootstrap CSS -->
  <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet">

  <style>
    body {
      background-color: #f8f9fa;
      font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
    }
    .transcription-box {
      background-color: #ffffff;
      border: 1px solid #dee2e6;
      border-radius: 8px;
      padding: 15px;
      min-height: 150px;
      box-shadow: 0 0 10px rgba(0, 0, 0, 0.05);
      white-space: pre-wrap;
    }
    .btn-custom {
      width: 150px;
    }
  </style>
</head>
<body>

  <div class="container py-5">
    <div class="text-center mb-4">
      <h2>üé§ Audio Transcription</h2>
      <p class="text-muted">Client-side speech-to-text using Web Speech API</p>
    </div>

    <div class="text-center mb-4">
      <button class="btn btn-success btn-custom me-2" onclick="startRecording()">Start Recording</button>
      <button class="btn btn-danger btn-custom" onclick="stopRecording()">Stop Recording</button>
    </div>

    <div>
      <h4>üìù Transcription Output:</h4>
      <div id="transcript" class="transcription-box"></div>
    </div>
  </div>

  <script>
    let finalTranscript = '';
    let recognition;
    let isRecording = false;

    if ('webkitSpeechRecognition' in window || 'SpeechRecognition' in window) {
      const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
      recognition = new SpeechRecognition();
      recognition.continuous = true;
      recognition.interimResults = true;
      recognition.lang = 'en-US';

      recognition.onresult = (event) => {
        let interimTranscript = '';
        for (let i = event.resultIndex; i < event.results.length; ++i) {
          const transcript = event.results[i][0].transcript;
          if (event.results[i].isFinal) {
            finalTranscript += transcript + ' ';
          } else {
            interimTranscript += transcript;
          }
        }
        document.getElementById('transcript').innerText = finalTranscript + interimTranscript;
      };

      recognition.onerror = (event) => {
        console.error("Speech recognition error:", event.error);
      };

      recognition.onend = () => {
        if (isRecording) {
          console.log("Recognition ended, restarting...");
          recognition.start(); // Auto-restart
        }
      };
    } else {
      alert("Your browser does not support Web Speech API. Try using Google Chrome.");
    }

    function startRecording() {
      finalTranscript = '';
      document.getElementById('transcript').innerText = '';
      isRecording = true;
      if (recognition) recognition.start();
    }

    function stopRecording() {
      isRecording = false;
      if (recognition) recognition.stop();
      console.log("Final Transcription:", finalTranscript);
    }
  </script>

</body>
</html>
